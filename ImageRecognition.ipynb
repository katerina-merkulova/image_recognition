{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f167b0e",
   "metadata": {},
   "source": [
    "## Install FaceNet\n",
    "\n",
    "**With pip:**\n",
    "`!sudo pip install facenet-pytorch`\n",
    "\n",
    "**or clone this repo, removing the '-' to allow python imports:**\n",
    "\n",
    "`!sudo git clone https://github.com/timesler/facenet-pytorch.git facenet_pytorch`\n",
    "\n",
    "**or use a docker container (see https://github.com/timesler/docker-jupyter-dl-gpu):**\n",
    "\n",
    "`!sudo docker run -it --rm timesler/jupyter-dl-gpu pip install facenet-pytorch && ipython`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a592a0c",
   "metadata": {},
   "source": [
    "## Get data\n",
    "`!sudo wget https://download.openmmlab.com/datasets/movienet/poster4M.img_meta.v1.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05ab790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "from imdb import IMDb\n",
    "import requests\n",
    "\n",
    "img_meta = json.load(open('poster4M.img_meta.v1.json'))\n",
    "ia = IMDb()\n",
    "\n",
    "p = Path.cwd() / 'data'\n",
    "shutil.rmtree(p, ignore_errors=True)\n",
    "p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "i = 1\n",
    "subsample = {}\n",
    "for image in img_meta:\n",
    "    if (img_meta[image]['type'] == 'event'    # Download only publicity type ~360K\n",
    "            and len(img_meta[image]['cast']) == 1):    # Only one person in photo\n",
    "        name_id = img_meta[image]['cast'][0][2:]\n",
    "        name = ia.get_person(name_id)['name']\n",
    "        url = img_meta[image]['url']\n",
    "\n",
    "        try:\n",
    "            r = requests.get(url)\n",
    "        except:\n",
    "            json.dump(subsample, open('subsample10K_meta.json', 'w'), indent=6)\n",
    "\n",
    "        img = r.content\n",
    "        if img == b'Not Found':\n",
    "            continue\n",
    "\n",
    "        folder = p / name\n",
    "        folder.mkdir(parents=True, exist_ok=True)\n",
    "        filepath = folder / f'{image}.jpg'\n",
    "        with filepath.open('wb') as out_file:\n",
    "            out_file.write(img)\n",
    "        i += 1\n",
    "        subsample[image] = img_meta[image]\n",
    "\n",
    "    if i == 1000:\n",
    "        break\n",
    "\n",
    "json.dump(subsample, open('subsample10K_meta.json', 'w'), indent=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737036ea",
   "metadata": {},
   "source": [
    "## Face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33ab831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff87362e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(x):\n",
    "    return x[0]\n",
    "\n",
    "dataset = datasets.ImageFolder(Path.cwd() / 'data_duplicated')\n",
    "dataset.idx_to_class = {i:c for c, i in dataset.class_to_idx.items()}\n",
    "loader = DataLoader(dataset, collate_fn=collate_fn)\n",
    "\n",
    "# If required, create a face detection pipeline using MTCNN:\n",
    "mtcnn = MTCNN(image_size=160, margin=32, device='cuda:0')\n",
    "\n",
    "# Create an inception resnet (in eval mode):\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to('cuda:0')\n",
    "\n",
    "aligned = []\n",
    "names = []\n",
    "\n",
    "i = 0\n",
    "for x, y in loader:\n",
    "    x_aligned = mtcnn(x)\n",
    "    if x_aligned is not None:\n",
    "        aligned.append(x_aligned)\n",
    "        names.append(dataset.idx_to_class[y])\n",
    "        i += 1\n",
    "    if i == 10:\n",
    "        break\n",
    "\n",
    "aligned = torch.stack(aligned).to('cuda:0')\n",
    "embeddings = resnet(aligned).detach().cpu()\n",
    "\n",
    "dists = [[(e1 - e2).norm().item() for e2 in embeddings] for e1 in embeddings]\n",
    "print(pd.DataFrame(dists, columns=names, index=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cc3f31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           nm0000006  nm0000006  nm0000007  nm0000007  nm0000008  nm0000008  \\\n",
      "nm0000006   0.000000   1.366138   1.090984   1.152431   1.230796   1.392182   \n",
      "nm0000006   1.366138   0.000000   1.368804   1.332926   1.372383   1.377241   \n",
      "nm0000007   1.090984   1.368804   0.000000   1.123659   1.151212   1.385094   \n",
      "nm0000007   1.152431   1.332926   1.123659   0.000000   1.156646   1.435622   \n",
      "nm0000008   1.230796   1.372383   1.151212   1.156646   0.000000   1.353558   \n",
      "nm0000008   1.392182   1.377241   1.385094   1.435622   1.353558   0.000000   \n",
      "nm0000009   1.258769   1.276305   1.336190   1.171455   1.308255   1.314605   \n",
      "nm0000011   0.961303   1.305481   1.333975   1.214338   1.162395   1.238129   \n",
      "nm0000011   1.096124   1.427237   1.240264   1.298536   1.464159   1.298635   \n",
      "nm0000012   1.396839   1.392042   1.388325   1.194588   1.355340   1.276682   \n",
      "\n",
      "           nm0000009  nm0000011  nm0000011  nm0000012  \n",
      "nm0000006   1.258769   0.961303   1.096124   1.396839  \n",
      "nm0000006   1.276305   1.305481   1.427237   1.392042  \n",
      "nm0000007   1.336190   1.333975   1.240264   1.388325  \n",
      "nm0000007   1.171455   1.214338   1.298536   1.194588  \n",
      "nm0000008   1.308255   1.162395   1.464159   1.355340  \n",
      "nm0000008   1.314605   1.238129   1.298635   1.276682  \n",
      "nm0000009   0.000000   1.228325   1.385910   1.321483  \n",
      "nm0000011   1.228325   0.000000   1.055728   1.244998  \n",
      "nm0000011   1.385910   1.055728   0.000000   1.397540  \n",
      "nm0000012   1.321483   1.244998   1.397540   0.000000  \n"
     ]
    }
   ],
   "source": [
    "aligned = torch.stack(aligned).to('cuda:0')\n",
    "embeddings = resnet(aligned).detach().cpu()\n",
    "\n",
    "dists = [[(e1 - e2).norm().item() for e2 in embeddings] for e1 in embeddings]\n",
    "print(pd.DataFrame(dists, columns=names, index=names))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e2bf2c84",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# If required, create a face detection pipeline using MTCNN:\n",
    "mtcnn = MTCNN(image_size=160, margin=32, device='cuda:0')\n",
    "\n",
    "# Create an inception resnet (in eval mode):\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to('cuda:0')\n",
    "\n",
    "p = Path.cwd() / 'data' / 'processed'\n",
    "shutil.rmtree(p, ignore_errors=True)\n",
    "p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "img_folder = Path.cwd() / 'data'\n",
    "img_dir = img_folder.glob('**/*.jpg')\n",
    "\n",
    "for img_name in img_dir:\n",
    "    img = Image.open(img_name)\n",
    "\n",
    "    # Get cropped and prewhitened image tensor\n",
    "    try:\n",
    "        image_cropped = mtcnn(img, save_path=str(img_folder/'processed'/img_name.name))\n",
    "    except (RuntimeError, TypeError) as error:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
