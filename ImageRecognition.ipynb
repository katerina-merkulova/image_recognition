{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f167b0e",
   "metadata": {},
   "source": [
    "## Install FaceNet\n",
    "\n",
    "**With pip:**\n",
    "`!sudo pip install facenet-pytorch`\n",
    "\n",
    "**or clone this repo, removing the '-' to allow python imports:**\n",
    "\n",
    "`!sudo git clone https://github.com/timesler/facenet-pytorch.git facenet_pytorch`\n",
    "\n",
    "**or use a docker container (see https://github.com/timesler/docker-jupyter-dl-gpu):**\n",
    "\n",
    "`!sudo docker run -it --rm timesler/jupyter-dl-gpu pip install facenet-pytorch && ipython`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a592a0c",
   "metadata": {},
   "source": [
    "## Get data\n",
    "`!sudo wget https://download.openmmlab.com/datasets/movienet/poster4M.img_meta.v1.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2463cdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "from imdb import IMDb\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05ab790",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_meta = json.load(open('poster4M.img_meta.v1.json'))\n",
    "ia = IMDb()\n",
    "\n",
    "p = Path.cwd() / 'data' / 'train_data'\n",
    "shutil.rmtree(p, ignore_errors=True)\n",
    "p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "i = 1\n",
    "subsample = {}\n",
    "for image in img_meta:\n",
    "    if (img_meta[image]['type'] == 'event'    # Download only publicity type ~360K\n",
    "            and len(img_meta[image]['cast']) == 1):    # Only one person in photo\n",
    "        name_id = img_meta[image]['cast'][0][2:]\n",
    "        name = ia.get_person(name_id)['name']\n",
    "        url = img_meta[image]['url']\n",
    "\n",
    "        r = requests.get(url)\n",
    "        img = r.content\n",
    "        if img == b'Not Found':\n",
    "            continue\n",
    "\n",
    "        folder = p / name\n",
    "        folder.mkdir(parents=True, exist_ok=True)\n",
    "        filepath = folder / f'{image}.jpg'\n",
    "        with filepath.open('wb') as out_file:\n",
    "            out_file.write(img)\n",
    "        i += 1\n",
    "        subsample[image] = img_meta[image]\n",
    "\n",
    "    if i == 1000:\n",
    "        break\n",
    "\n",
    "json.dump(subsample, open('subsample10K_meta.json', 'w'), indent=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8e92e9",
   "metadata": {},
   "source": [
    "## Train test val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21866f61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val for Emma Roberts\n",
      "val for Mila Kunis\n",
      "val for Andrew Garfield\n",
      "val for Martin Landau\n",
      "val for Jennifer Lawrence\n",
      "val for Rob Lowe\n",
      "val for Ashley Greene\n",
      "val for Gwendoline Christie\n",
      "val for Marg Helgenberger\n",
      "val for Ryan Seacrest\n",
      "val for Sam Rockwell\n",
      "val for Bonnie Wright\n",
      "val for Paris Hilton\n",
      "val for Matthias Schoenaerts\n",
      "val for Tracee Ellis Ross\n",
      "val for Carrie Underwood\n",
      "val for Angus T\n",
      "val for Christina Applegate\n",
      "val for Cate Blanchett\n",
      "val for Annie Wersching\n",
      "val for Jonah Hill\n",
      "val for Joey Soloway\n",
      "val for Lea Michele\n",
      "val for Sharon Stone\n",
      "val for Scarlett Johansson\n",
      "val for Bobby Cannavale\n",
      "val for Halle Berry\n",
      "val for Carmen Electra\n",
      "val for Emmy Rossum\n",
      "val for Jessica Simpson\n",
      "val for Gerard Butler\n",
      "val for Aishwarya Rai Bachchan\n",
      "val for Meagan Good\n",
      "val for Tony Bennett\n",
      "val for Bob Hope\n",
      "val for Jessica Alba\n",
      "val for Ali Larter\n",
      "val for Chris Tucker\n",
      "val for Arjit Taneja\n",
      "val for Joel Edgerton\n",
      "val for Kate Mara\n",
      "val for Jack Nicholson\n",
      "val for Lady Gaga\n",
      "val for Cheryl Hines\n",
      "val for Will Smith\n",
      "val for Dakota Johnson\n",
      "val for Olivier De Funès\n",
      "val for Daisy Fuentes\n",
      "val for Taraji P\n",
      "val for Garcelle Beauvais\n",
      "val for Vince Vaughn\n",
      "val for Beyoncé\n",
      "val for Lisa Kudrow\n",
      "val for Ryan Gosling\n",
      "val for Taylor Swift\n",
      "val for Rex Lee\n",
      "val for Kay Panabaker\n",
      "val for Michelle Williams\n",
      "val for AnnaLynne McCord\n",
      "val for Naomi Watts\n",
      "val for Matthew McConaughey\n",
      "val for Julianne Moore\n",
      "val for Dakota Fanning\n",
      "val for Charlize Theron\n",
      "val for Vanessa Carlton\n",
      "val for Kate Hudson\n",
      "val for Chace Crawford\n",
      "val for Dascha Polanco\n",
      "val for Amanda Bynes\n",
      "val for Rose McGowan\n",
      "val for Katharine Towne\n",
      "val for Alec Baldwin\n",
      "val for Edward Norton\n",
      "val for Jessica Chastain\n",
      "val for Zachary Levi\n",
      "val for Selena Gomez\n",
      "val for Jim Rash\n",
      "val for Sarah McLachlan\n",
      "val for Tester McTesterwitz\n",
      "val for Selita Ebanks\n",
      "val for Serena Williams\n",
      "val for Lindsay Lohan\n",
      "val for Dwayne Johnson\n",
      "val for Emma Stone\n",
      "val for Jennifer Jason Leigh\n",
      "val for Mandy Moore\n",
      "val for Kristen Bell\n",
      "val for Harrison Ford\n",
      "val for Margot Robbie\n",
      "val for Eva Mendes\n",
      "val for Viola Davis\n",
      "val for Renée Zellweger\n",
      "val for Cameron Diaz\n",
      "val for Annette Bening\n",
      "val for Jessica Stroup\n",
      "val for Carla Gugino\n",
      "val for Shenae Grimes-Beech\n",
      "val for Nicole Kidman\n",
      "val for Troian Bellisario\n",
      "val for Nina Dobrev\n",
      "test for Amber Tamblyn\n",
      "test for Sophia Bush\n",
      "test for Miley Cyrus\n"
     ]
    }
   ],
   "source": [
    "p = Path.cwd() / 'data' / 'train_data'\n",
    "test_path = Path.cwd() / 'data' / 'test_data'\n",
    "test_path.mkdir(parents=True, exist_ok=True)\n",
    "val_path = Path.cwd() / 'data' / 'val_data'\n",
    "val_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "i = 0\n",
    "for actor in p.iterdir():\n",
    "    images = list(actor.iterdir())\n",
    "    if len(images) > 1:    # Half in val and half in test\n",
    "        if i < 100:\n",
    "            print(f'val for {actor.stem}')\n",
    "\n",
    "            actor_folder = val_path / actor.stem\n",
    "            actor_folder.mkdir(parents=True, exist_ok=True)\n",
    "            for image in images[1:]:    # Leave first photo in train\n",
    "                image.rename(actor_folder / image.name)\n",
    "        else:\n",
    "            print(f'test for {actor.stem}')\n",
    "\n",
    "            actor_folder = test_path / actor.stem\n",
    "            actor_folder.mkdir(parents=True, exist_ok=True)\n",
    "            for image in images[1:]:\n",
    "                image.rename(actor_folder / image.name)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0a985e67",
   "metadata": {},
   "source": [
    "p = Path.cwd() / 'data' / 'train_data'\n",
    "test_path = Path.cwd() / 'data' / 'test_data'\n",
    "val_path = Path.cwd() / 'data' / 'val_data'\n",
    "\n",
    "for actor in test_path.iterdir():\n",
    "    images = list(actor.iterdir())\n",
    "    actor_folder = p / actor.stem\n",
    "    for image in images:\n",
    "        image.rename(actor_folder / image.name)\n",
    "\n",
    "for actor in val_path.iterdir():\n",
    "    images = list(actor.iterdir())\n",
    "    actor_folder = p / actor.stem\n",
    "    for image in images:\n",
    "        image.rename(actor_folder / image.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737036ea",
   "metadata": {},
   "source": [
    "## Face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf85c7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1, fixed_image_standardization, training\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "392f58ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 of 26\n",
      "Batch 2 of 26\n",
      "Batch 3 of 26\n",
      "Batch 4 of 26\n",
      "Batch 5 of 26\n",
      "Batch 6 of 26\n",
      "Batch 7 of 26\n",
      "Batch 8 of 26\n",
      "Batch 9 of 26\n",
      "Batch 10 of 26\n",
      "Batch 11 of 26\n",
      "Batch 12 of 26\n",
      "Batch 13 of 26\n",
      "Batch 14 of 26\n",
      "Batch 15 of 26\n",
      "Batch 16 of 26\n",
      "Batch 17 of 26\n",
      "Batch 18 of 26\n",
      "Batch 19 of 26\n",
      "Batch 20 of 26\n",
      "Batch 21 of 26\n",
      "Batch 22 of 26\n",
      "Batch 23 of 26\n",
      "Batch 24 of 26\n",
      "Batch 25 of 26\n",
      "Batch 26 of 26\n",
      "Batch 1 of 5\n",
      "Batch 2 of 5\n",
      "Batch 3 of 5\n",
      "Batch 4 of 5\n",
      "Batch 5 of 5\n",
      "Batch 1 of 1\n"
     ]
    }
   ],
   "source": [
    "def detection(folder, mtcnn):\n",
    "\n",
    "    data_dir = Path.cwd() / 'data' / f'{folder}_data'\n",
    "    target_dir = Path.cwd() / 'data' / f'{folder}_data_cropped'\n",
    "\n",
    "    dataset = datasets.ImageFolder(data_dir, transform=transforms.Resize((512, 512)))\n",
    "    dataset.samples = [\n",
    "        (p, \n",
    "         target_dir / Path(p).parents[0].name / Path(p).name)\n",
    "         for p, _ in dataset.samples\n",
    "    ]\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        num_workers=workers,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=training.collate_pil\n",
    "    )\n",
    "\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        mtcnn(x, save_path=y)\n",
    "        print(f'Batch {i + 1} of {len(loader)}')\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "workers = 8\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "mtcnn = MTCNN(\n",
    "image_size=160, margin=0, min_face_size=20,\n",
    "thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
    "device=device\n",
    ")\n",
    "\n",
    "detection('train', mtcnn)\n",
    "detection('val', mtcnn)\n",
    "detection('test', mtcnn)\n",
    "\n",
    "# Remove mtcnn to reduce GPU memory usage\n",
    "del mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0d91a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    np.float32,\n",
    "    transforms.ToTensor(),\n",
    "    fixed_image_standardization\n",
    "])\n",
    "train_dataset = datasets.ImageFolder(Path.cwd() / 'data' / 'train_data_cropped', transform=trans)\n",
    "val_dataset = datasets.ImageFolder(Path.cwd() / 'data' / 'val_data_cropped', transform=trans)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "resnet = InceptionResnetV1(\n",
    "    classify=True,\n",
    "    pretrained='vggface2',\n",
    "    num_classes=len(train_dataset.class_to_idx)\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(resnet.parameters(), lr=0.001)\n",
    "scheduler = MultiStepLR(optimizer, [5, 10])\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "metrics = {\n",
    "    'fps': training.BatchTimer(),\n",
    "    'acc': training.accuracy\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82e66c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Initial\n",
      "----------\n",
      "Valid |     4/4    | loss:    6.7171 | fps: 1000.5200 | acc:    0.0000   \n",
      "\n",
      "Epoch 1/20\n",
      "----------\n",
      "Train |    26/26   | loss:    6.8626 | fps:  374.6056 | acc:    0.0000   \n",
      "Valid |     4/4    | loss:   32.9526 | fps: 1199.0618 | acc:    0.0000   \n",
      "\n",
      "Epoch 2/20\n",
      "----------\n",
      "Train |    26/26   | loss:    6.4969 | fps:  373.6603 | acc:    0.0012   \n",
      "Valid |     4/4    | loss:    7.1146 | fps: 1171.3794 | acc:    0.0000   \n",
      "\n",
      "Epoch 3/20\n",
      "----------\n",
      "Train |    26/26   | loss:    5.7804 | fps:  369.0317 | acc:    0.0149   \n",
      "Valid |     4/4    | loss:    7.9866 | fps: 1256.4624 | acc:    0.0000   \n",
      "\n",
      "Epoch 4/20\n",
      "----------\n",
      "Train |    26/26   | loss:    5.1175 | fps:  379.3522 | acc:    0.0608   \n",
      "Valid |     4/4    | loss:    7.8780 | fps: 1355.4856 | acc:    0.0000   \n",
      "\n",
      "Epoch 5/20\n",
      "----------\n",
      "Train |    26/26   | loss:    4.5633 | fps:  368.9289 | acc:    0.1137   \n",
      "Valid |     4/4    | loss:    7.7459 | fps: 1227.7445 | acc:    0.0000   \n",
      "\n",
      "Epoch 6/20\n",
      "----------\n",
      "Train |    26/26   | loss:    3.9512 | fps:  371.4224 | acc:    0.3221   \n",
      "Valid |     4/4    | loss:    7.7063 | fps: 1229.0388 | acc:    0.0000   \n",
      "\n",
      "Epoch 7/20\n",
      "----------\n",
      "Train |    26/26   | loss:    3.3966 | fps:  367.1595 | acc:    0.4820   \n",
      "Valid |     4/4    | loss:    7.6151 | fps: 1326.5071 | acc:    0.0000   \n",
      "\n",
      "Epoch 8/20\n",
      "----------\n",
      "Train |    26/26   | loss:    3.1429 | fps:  374.5469 | acc:    0.5925   \n",
      "Valid |     4/4    | loss:    7.6289 | fps: 1039.6481 | acc:    0.0000   \n",
      "\n",
      "Epoch 9/20\n",
      "----------\n",
      "Train |    26/26   | loss:    2.9334 | fps:  372.4773 | acc:    0.7067   \n",
      "Valid |     4/4    | loss:    7.6371 | fps: 1357.4648 | acc:    0.0000   \n",
      "\n",
      "Epoch 10/20\n",
      "----------\n",
      "Train |    26/26   | loss:    2.7551 | fps:  376.3892 | acc:    0.7764   \n",
      "Valid |     4/4    | loss:    7.6812 | fps: 1225.2850 | acc:    0.0000   \n",
      "\n",
      "Epoch 11/20\n",
      "----------\n",
      "Train |    26/26   | loss:    2.5697 | fps:  375.6244 | acc:    0.8221   \n",
      "Valid |     4/4    | loss:    7.7027 | fps: 1203.4110 | acc:    0.0000   \n",
      "\n",
      "Epoch 12/20\n",
      "----------\n",
      "Train |    26/26   | loss:    2.5370 | fps:  366.3523 | acc:    0.8425   \n",
      "Valid |     4/4    | loss:    7.7016 | fps: 1274.2822 | acc:    0.0000   \n",
      "\n",
      "Epoch 13/20\n",
      "----------\n",
      "Train |    26/26   | loss:    2.5274 | fps:  372.0466 | acc:    0.8438   \n",
      "Valid |     4/4    | loss:    7.7031 | fps: 1282.9906 | acc:    0.0000   \n",
      "\n",
      "Epoch 14/20\n",
      "----------\n",
      "Train |    26/26   | loss:    2.4979 | fps:  378.3072 | acc:    0.8582   \n",
      "Valid |     4/4    | loss:    7.7221 | fps: 1149.5239 | acc:    0.0000   \n",
      "\n",
      "Epoch 15/20\n",
      "----------\n",
      "Train |    26/26   | loss:    2.4840 | fps:  370.3571 | acc:    0.8594   \n",
      "Valid |     4/4    | loss:    7.7119 | fps: 1226.3378 | acc:    0.0000   \n",
      "\n",
      "Epoch 16/20\n",
      "----------\n",
      "Train |    26/26   | loss:    2.4693 | fps:  369.0574 | acc:    0.8690   \n",
      "Valid |     4/4    | loss:    7.7284 | fps: 1048.4800 | acc:    0.0000   \n",
      "\n",
      "Epoch 17/20\n",
      "----------\n",
      "Train |    26/26   | loss:    2.4522 | fps:  368.1304 | acc:    0.8618   \n",
      "Valid |     4/4    | loss:    7.7262 | fps: 1183.7222 | acc:    0.0000   \n",
      "\n",
      "Epoch 18/20\n",
      "----------\n",
      "Train |    26/26   | loss:    2.4241 | fps:  377.7785 | acc:    0.8690   \n",
      "Valid |     4/4    | loss:    7.7151 | fps: 1233.2935 | acc:    0.0000   \n",
      "\n",
      "Epoch 19/20\n",
      "----------\n",
      "Train |    26/26   | loss:    2.4081 | fps:  370.5074 | acc:    0.8942   \n",
      "Valid |     4/4    | loss:    7.7348 | fps: 1222.6069 | acc:    0.0000   \n",
      "\n",
      "Epoch 20/20\n",
      "----------\n",
      "Train |    26/26   | loss:    2.3791 | fps:  369.8825 | acc:    0.8810   \n",
      "Valid |     4/4    | loss:    7.7346 | fps: 1212.5302 | acc:    0.0000   \n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "writer.iteration, writer.interval = 0, 10\n",
    "\n",
    "print('\\n\\nInitial')\n",
    "print('-' * 10)\n",
    "resnet.eval()\n",
    "training.pass_epoch(\n",
    "    resnet, loss_fn, val_loader,\n",
    "    batch_metrics=metrics, show_running=True, device=device,\n",
    "    writer=writer\n",
    ")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'\\nEpoch {epoch + 1}/{epochs}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    resnet.train()\n",
    "    training.pass_epoch(\n",
    "        resnet, loss_fn, train_loader, optimizer, scheduler,\n",
    "        batch_metrics=metrics, show_running=True, device=device,\n",
    "        writer=writer\n",
    "    )\n",
    "\n",
    "    resnet.eval()\n",
    "    training.pass_epoch(\n",
    "        resnet, loss_fn, val_loader,\n",
    "        batch_metrics=metrics, show_running=True, device=device,\n",
    "        writer=writer\n",
    "    )\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3e20f2",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3aff67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amber Tamblyn</th>\n",
       "      <th>Miley Cyrus</th>\n",
       "      <th>Miley Cyrus</th>\n",
       "      <th>Sophia Bush</th>\n",
       "      <th>Sophia Bush</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Amber Tamblyn</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.249657</td>\n",
       "      <td>54.715439</td>\n",
       "      <td>76.937408</td>\n",
       "      <td>64.829414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miley Cyrus</th>\n",
       "      <td>36.249657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.707031</td>\n",
       "      <td>68.722832</td>\n",
       "      <td>65.746277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miley Cyrus</th>\n",
       "      <td>54.715439</td>\n",
       "      <td>67.707031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.272041</td>\n",
       "      <td>56.119682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sophia Bush</th>\n",
       "      <td>76.937408</td>\n",
       "      <td>68.722832</td>\n",
       "      <td>78.272041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.222034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sophia Bush</th>\n",
       "      <td>64.829414</td>\n",
       "      <td>65.746277</td>\n",
       "      <td>56.119682</td>\n",
       "      <td>42.222034</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Amber Tamblyn  Miley Cyrus  Miley Cyrus  Sophia Bush  \\\n",
       "Amber Tamblyn       0.000000    36.249657    54.715439    76.937408   \n",
       "Miley Cyrus        36.249657     0.000000    67.707031    68.722832   \n",
       "Miley Cyrus        54.715439    67.707031     0.000000    78.272041   \n",
       "Sophia Bush        76.937408    68.722832    78.272041     0.000000   \n",
       "Sophia Bush        64.829414    65.746277    56.119682    42.222034   \n",
       "\n",
       "               Sophia Bush  \n",
       "Amber Tamblyn    64.829414  \n",
       "Miley Cyrus      65.746277  \n",
       "Miley Cyrus      56.119682  \n",
       "Sophia Bush      42.222034  \n",
       "Sophia Bush       0.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def collate_fn(x):\n",
    "    return x[0]\n",
    "\n",
    "test_dataset = datasets.ImageFolder(Path.cwd() / 'data' / 'test_data')\n",
    "test_dataset.idx_to_class = {i:c for c, i in test_dataset.class_to_idx.items()}\n",
    "test_loader = DataLoader(test_dataset, collate_fn=collate_fn)\n",
    "\n",
    "mtcnn = MTCNN(\n",
    "image_size=160, margin=0, min_face_size=20,\n",
    "thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
    "device=device\n",
    ")\n",
    "\n",
    "resnet.eval().to(device)\n",
    "\n",
    "aligned = []\n",
    "names = []\n",
    "\n",
    "i = 0\n",
    "for x, y in test_loader:\n",
    "    x_aligned = mtcnn(x)\n",
    "    if x_aligned is not None:\n",
    "        aligned.append(x_aligned)\n",
    "        names.append(test_dataset.idx_to_class[y])\n",
    "        i += 1\n",
    "    if i == 10:\n",
    "        break\n",
    "\n",
    "aligned = torch.stack(aligned).to(device)\n",
    "embeddings = resnet(aligned).detach().cpu()\n",
    "\n",
    "dists = [[(e1 - e2).norm().item() for e2 in embeddings] for e1 in embeddings]\n",
    "pd.DataFrame(dists, columns=names, index=names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
